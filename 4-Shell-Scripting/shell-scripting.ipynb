{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjIE4q49Yi69"
      },
      "outputs": [],
      "source": [
        "# Before we begin, run this cell if you are using Colab\n",
        "!git clone https://github.com/danielinux7/StemLab.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu9ptwgOYi7K"
      },
      "source": [
        "# Shell Scripting\n",
        "\n",
        "#### Content\n",
        "1. Shell commands (shuf, wc, grep, sed, sort, uniq, cat, head, tail)\n",
        "2. Regular Expressions (regex)\n",
        "\n",
        "#### What you will be able to do after the tutorial\n",
        "* Extract text from pdf (data dump).\n",
        "* Text clean up, remove undesired output.\n",
        "* Learn about regex.\n",
        "* Fix common issues.\n",
        "* Split text into sentences.\n",
        "* Build a parallel corpus.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Extract text from pdf (data dump)**"
      ],
      "metadata": {
        "id": "drhxXSQE4Dzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "j30qh3tf4Xo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing required modules\n",
        "import PyPDF2\n",
        "import sys\n",
        "\n",
        "# store standard output to restore it later\n",
        "origin_stdout = sys.stdout\n",
        "\n",
        "# creating a pdf file object\n",
        "pdfFileObj_ab = open('/content/StemLab/4-Shell-Scripting/last-of-the-departed_ ab.pdf', 'rb')\n",
        "pdfFileObj_ru = open('/content/StemLab/4-Shell-Scripting/last-of-the-departed_ ru.pdf', 'rb')\n",
        "\n",
        "# creating a pdf reader object\n",
        "pdfReader_ab = PyPDF2.PdfFileReader(pdfFileObj_ab)\n",
        "pdfReader_ru = PyPDF2.PdfFileReader(pdfFileObj_ru)\n",
        "\n",
        "# extracting text from pdf\n",
        "sys.stdout = open(\"ab.txt\", \"w\")\n",
        "for i in range(pdfReader_ab.numPages):\n",
        "    current_page = pdfReader_ab.getPage(i)\n",
        "    print(current_page.extractText())\n",
        "\n",
        "sys.stdout = open(\"ru.txt\", \"w\")\n",
        "for i in range(pdfReader_ru.numPages):\n",
        "    current_page = pdfReader_ru.getPage(i)\n",
        "    print(current_page.extractText())\n",
        "    \n",
        "sys.stdout = origin_stdout\n",
        "# closing the pdf file object\n",
        "pdfFileObj_ab.close()\n",
        "pdfFileObj_ru.close()\n"
      ],
      "metadata": {
        "id": "wQjdvSDS241_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Text clean up, remove undesired output**\n",
        "\n",
        "The extracted text from pdf files need a lot of clean up, first thing to do is to look at the txt files, to firgure out similiar noise patterns.\n",
        "\n",
        "Eventually we will use shell commands and scripting to accomplish our goal, the reason for using shell commands because they have fast execution time, this is very import in big data."
      ],
      "metadata": {
        "id": "4PLJncum92-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**File stats:** understanding some details about the files that we are dealing with, "
      ],
      "metadata": {
        "id": "4MhauaZxLKZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the number of lines, words and characters of our files\n",
        "!wc ab.txt ru.txt"
      ],
      "metadata": {
        "id": "xL7PFh8ELqw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the number of lines of our files\n",
        "!wc -l ab.txt\n",
        "!wc -l ru.txt"
      ],
      "metadata": {
        "id": "ozy2NM4WMOL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Peak at the files:**\n",
        "The files we are dealing with are usually big, so we can take a look at small parts withthe commands head, tail or sed"
      ],
      "metadata": {
        "id": "3-ZCshJvARQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show first 20 lines with head in a text file\n",
        "!head -20 ab.txt "
      ],
      "metadata": {
        "id": "Ey5r19YqBNdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the last 20 lines with tail in a text file\n",
        "!tail -20 ru.txt "
      ],
      "metadata": {
        "id": "J-bIGAkKH-ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the lines from 4 to 8 in a text file\n",
        "!sed -n '4,8p' ab.txt"
      ],
      "metadata": {
        "id": "QItJvo-SI_yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove extra lines:** we need to remove empty lines, lines with empy space, lines with symbols that won't be useful for our translation task."
      ],
      "metadata": {
        "id": "N5bnesYdMver"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove empty lines from the text file, we use piping \"|\" to chain the inputs and outputs of our commands\n",
        "!head -20 ab.txt | sed -r '/^$/d'"
      ],
      "metadata": {
        "id": "gCke46L4NVn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Question:* why we shouldn't do this?\n",
        "```!sed -r '/^$/d' ab.txt | head -20```\n",
        "\n"
      ],
      "metadata": {
        "id": "WvKOS7h-Pea5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's remove also lines with empty spaces\n",
        "!head -20 ab.txt | sed -r '/^$/d' | sed -r '/^[ ]+$/d'"
      ],
      "metadata": {
        "id": "OdVx_Lw4QDON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In our case for the machine translation task, we only care about the lines \n",
        "# that have alphabetical characters for Russian and Abkhazian.\n",
        "!head -20 ab.txt | sed -n '/[[:alpha:]]/p'\n",
        "print()\n",
        "!head -20 ru.txt | sed -n '/[[:alpha:]]/p'"
      ],
      "metadata": {
        "id": "Mz8NQfQrQqdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We process the files with sed and save the results in the same files, then we check out their stats.\n",
        "!sed -i -n '/[[:alpha:]]/p' ab.txt\n",
        "!sed -i -n '/[[:alpha:]]/p' ru.txt\n",
        "!wc ab.txt\n",
        "!wc ru.txt"
      ],
      "metadata": {
        "id": "iCbYsnWXTXNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Learn about regex**\n",
        "\n",
        "*   What is regex?\n",
        " \n",
        " A **Reg**ular **Ex**pression (regex) is a sequence of characters that specifies a search pattern in text. Usually such patterns are used by string-searching algorithms for \"find\" or \"find and replace\" operations on strings, or for input validation.\n",
        "\n",
        "*   Where would we use regex?\n",
        " \n",
        " Regular expressions are used in search engines, in search and replace dialogs of word processors and text editors, in text processing utilities such as sed and AWK, and in lexical analysis. Most general-purpose programming languages support regex capabilities either natively or via libraries, including for example Python, C, C++, Java, and JavaScript.\n",
        "\n",
        "* What is regex syntax?\n",
        "\n",
        "1.   [POSIX_basic](https://en.wikipedia.org/wiki/Regular_expression#POSIX_basic_and_extended)\n",
        "2.   [POSIX extended](https://en.wikipedia.org/wiki/Regular_expression#POSIX_extended)\n",
        "3.   [Character classes](https://en.wikipedia.org/wiki/Regular_expression#Character_classes)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pe7PAl6ATNZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Fix common issues**"
      ],
      "metadata": {
        "id": "Dfp2euXQiYKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace non-breaking space with usual space\n",
        "# Remove extra space\n",
        "# Remove page numbers sticked to a word at the beginning of a line\n",
        "# Words and sentences break to the next line\n",
        "!sed -r 's/\\xC2\\xA0/ /g' ab.txt | \\\n",
        " sed -r 's/[ ]+/ /g' | \\\n",
        " sed -r 's/^[0-9]+([[:alpha:]–])/\\1/g' | \\\n",
        " sed -z -r 's/([[:lower:] ])[- ]*\\n([[:lower:] «])/\\1\\2/g' | head -100\n"
      ],
      "metadata": {
        "id": "fOulEH0U-Hd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYzianchYi8w"
      },
      "source": [
        "## Additional resources/references:\n",
        "\n",
        "* [Document Object Model (DOM)](https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model/Introduction)\n",
        "* [HTML elements reference guide](https://www.w3schools.com/tags/default.asp)\n",
        "* [About /robots.txt](https://www.robotstxt.org/robotstxt.html)\n",
        "* [The robots.txt file](https://varvy.com/robottxt.html)\n",
        "* [Ethics in Web Scraping](https://towardsdatascience.com/ethics-in-web-scraping-b96b18136f01)\n",
        "* [On the Ethics of Web Scraping](http://robertorocha.info/on-the-ethics-of-web-scraping/)\n",
        "* [User-Agent](https://en.wikipedia.org/wiki/User_agent)\n",
        "* [BeautifulSoup documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
        "* [Selinium Python - Unofficial documentation](https://selenium-python.readthedocs.io/)\n",
        "* [ARGUS paper](http://ftp.zew.de/pub/zew-docs/dp/dp18033.pdf)\n",
        "* [Brian's C. Keegan](http://www.brianckeegan.com/) excellent [5-week web scraping course](https://github.com/CU-ITSS/Web-Data-Scraping-S2019) intended for researchers in the social sciences and humanities."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:py36]",
      "language": "python",
      "name": "conda-env-py36-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "shell-scripting.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}